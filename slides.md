---
theme: seriph
layout: center
title: Data Science for Community Engaged Research
---

# Data Science for Community Engaged Research

Here's where I'll put my (Jeremy's) info and stuff about the projects generally.

---
layout: two-cols-header
---

# Neha Anil Chede

- What did you accomplish? What were the results, products, code, or other deliverables that you provided?
- What did you learn? What skills did you acquire?
- Any concluding thoughts about your experience?

::left::

# Kirthivasan Pandurangan Neelavathi

- What did you accomplish? What were the results, products, code, or other deliverables that you provided?
- What did you learn? What skills did you acquire?
- Any concluding thoughts about your experience?

::right::

# Vivek Tiwari

- What did you accomplish? What were the results, products, code, or other deliverables that you provided?
  - For the Center-IMPACT project:
  - I single-handedly developed a comprehensive Streamlit frontend, creating an intuitive interface for project creation, survey forms, and real-time score calculations. This streamlined the entire process of evaluating community-engaged research projects.
  - I architected and implemented a sophisticated Neo4j graph database, modeling intricate relationships between project entities. This complex structure allows for powerful querying and analysis, providing deeper insights into research impact.
  - I crafted a custom API that seamlessly connects the frontend and backend, ensuring smooth data flow and enhancing overall system performance.
  - I took charge of deployment, automating hosting with Streamlit cloud and implementing robust CI/CD pipelines on GitHub. This significantly improved our development workflow and ensured consistent, reliable updates.
  - Throughout the development phase, I managed the hosting environment, providing a stable platform for testing and iteration, which was crucial for the project's success.
  
  - For the Center-SEEK project:
  - I engineered an advanced web scraping script that efficiently collected news articles from multiple university websites, overcoming various technical challenges to gather a diverse dataset.
  - I designed and trained a Feedforward Neural Network that achieved an impressive 71% accuracy in classifying community-engaged research articles, despite the initial limited dataset.
  - To overcome data scarcity, I implemented a suite of complex NLP data augmentation techniques. This included synonym replacement using WordNet, strategic word swapping and deletion, and contextual word insertion using BERT. These techniques dramatically expanded our training data.
  - Through my efforts, I transformed a limited initial dataset of just 92 articles into a robust training set, significantly enhancing the model's learning capabilities and overall performance.

- What did you learn? What skills did you acquire?
  Through these projects, I significantly expanded my expertise:
  - I mastered Streamlit for rapid frontend development, learning to create responsive, data-centric web applications efficiently.
  - I gained advanced skills in Neo4j, developing a deep understanding of graph database design principles and their real-world applications.
  - I honed my web scraping techniques, learning to navigate complex website structures and extract relevant data effectively.
  - I became proficient in cutting-edge NLP data augmentation methods, gaining hands-on experience with tools like WordNet and BERT.
  - I deepened my understanding of neural network architecture, particularly in designing and fine-tuning Feedforward Neural Networks for text classification tasks.
  - I strengthened my DevOps skills through implementing CI/CD pipelines and managing cloud hosting, enhancing my ability to streamline development workflows.
  - I improved my API development skills, learning to create robust interfaces for seamless system integration.
  - I developed innovative strategies for handling small datasets, acquiring valuable skills in data preprocessing and augmentation for machine learning applications.
  - I gained practical experience in applying deep learning techniques to real-world text classification challenges.
  - I enhanced my project management abilities, successfully overseeing end-to-end development from initial data collection to final model deployment.

- Any concluding thoughts about your experience?
  - These projects were transformative for my professional growth. I tackled complex, real-world challenges in community-engaged research, pushing the boundaries of my technical abilities. The experience of overcoming data limitations through creative NLP techniques was particularly enlightening and has equipped me with valuable problem-solving skills. I demonstrated my versatility by seamlessly transitioning between frontend development, backend architecture, machine learning, and DevOps. This interdisciplinary approach allowed me to create comprehensive solutions that bridge technical implementation and domain-specific needs.
  - The projects also honed my ability to work independently and take ownership of critical components. From designing database structures to implementing machine learning models, I drove key aspects of both projects to successful completion.
  Perhaps most importantly, these experiences have instilled in me a confidence to take on ambitious, multifaceted projects. I've proven my ability to quickly adapt to new technologies and methodologies, positioning myself as a versatile and valuable asset for future technological challenges.
  - As I reflect on these projects, I'm excited about the foundation they've provided for my future work. I'm now well-equipped to tackle even more complex challenges, contribute to cutting-edge research, and continue pushing the boundaries of what's possible in community-engaged tech solutions.
